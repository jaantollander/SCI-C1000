<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Indoor Navigation from Multiple Images</title><link href="https://jaantollander.github.io/SCI-C1000/" rel="alternate"></link><link href="https://jaantollander.github.io/SCI-C1000/feeds/all.atom.xml" rel="self"></link><id>https://jaantollander.github.io/SCI-C1000/</id><updated>2016-11-24T00:00:00+02:00</updated><entry><title>Invitation to Grand Finale at 2016-12-09</title><link href="https://jaantollander.github.io/SCI-C1000/grand-finale-invitation.html" rel="alternate"></link><published>2016-11-24T00:00:00+02:00</published><updated>2016-11-24T00:00:00+02:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-11-24:SCI-C1000/grand-finale-invitation.html</id><summary type="html">&lt;!-- Where, When, What --&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="https://jaantollander.github.io/3D-models/aula/examples/aula.html"&gt;&lt;img alt="model" src="images/aula2.png" style="width: 100%;" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Our team warmly welcomes you to hear our presentation and further investigate our results about &lt;em&gt;indoor navigation using point cloud from photos&lt;/em&gt;  on &lt;strong&gt;december 9th&lt;/strong&gt;. Presentations are held at Aalto University main building lobby in &lt;strong&gt;Otakaari 1&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;During this fall our project group has been researching a new innovative method for indoor navigation using &lt;em&gt;structure from motion&lt;/em&gt; and crowd sourced photos. We have estimated its potential and possibilities.&lt;/p&gt;
&lt;p&gt;This kind of navigation is made possible with &lt;em&gt;structure from motion&lt;/em&gt; technology which makes generating 3D models from multiple ordinary photos possible. Generated point cloud can be used for indoor navigation and dense reconstruction (3D model with texture) offers the possibility of using augmented reality elements.&lt;/p&gt;
&lt;p&gt;You can read more about our research from the blog and these posts&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://jaantollander.github.io/SCI-C1000/comparison.html"&gt;Comparison Between Indoor Navigation Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://jaantollander.github.io/SCI-C1000/prototype.html"&gt;Creating the Prototype&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
</summary><category term="grand finale invitation"></category></entry><entry><title>Analysis of Presentation Video</title><link href="https://jaantollander.github.io/SCI-C1000/video-analysis.html" rel="alternate"></link><published>2016-11-24T00:00:00+02:00</published><updated>2016-11-24T00:00:00+02:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-11-24:SCI-C1000/video-analysis.html</id><summary type="html">&lt;!-- Slides --&gt;
&lt;!-- Video --&gt;
&lt;p&gt;&lt;a class="reference external" href="https://jaantollander.github.io/SCI-C1000/downloads/presentation_11-18-2016.pptx"&gt;Presentation slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://jaantollander.github.io/SCI-C1000/downloads/video_2016-11-24_17-06-07.mov"&gt;Video of the presentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The goal of this presentation was to give general idea of our oncoming prototype and the progress of the overall project. In general this goal was achieved and presentation got audience interested of our project and prototype. There were still many points left to improve in presentations to come.&lt;/p&gt;
&lt;p&gt;Overall our presentation was focused on point and didn’t stray from topic. Also the speak was clear and loud enough to be followed easily. However we should have practiced more co-operation between speakers and the slide operator. This was most visible when speakers had to ask for slides or change them by themselves. Also the person speaking should stand out better from the rest of the group.&lt;/p&gt;
&lt;p&gt;The start of presentation was energetic and went straight to the point so that our topic was crystal clear for everyone from the beginning. The flow was interrupted when the next speaker had to switch between programs to present our prototype. In next presentations we’ll avoid this issue by keeping the whole presentation in powerpoint and presenting prototype with images and videos. The presentation of prototype was also way too long compared to other parts of presentation, but it was clearly the most interesting part of this presentation. It was also good that we chose to present the test model from dumpster, which got excellent feedback from the audience.&lt;/p&gt;
&lt;p&gt;After presenting the prototype and switching to market potential and next steps the first speaker didn’t have the same contact to the audience anymore. In the market research part it would have been good to give concrete numbers instead of saying that it has “huge” potential. Although the time limit was already exceeded at that point, the presentation was still intact and complete and wasn’t rushed through last parts. The ending of the presentation was also a bit flat when the speaker didn’t give any conclusion and went straight to the questions. It would have been better to gather the main points of the presentation together and thank the audience.&lt;/p&gt;
&lt;p&gt;Despite many improvement areas, the presentation succeeded in its goals and it was followed by a long and interesting discussion with the audience. There was also clearly interest to trying our final prototype in Grand Finale, which was encouraging for the team.&lt;/p&gt;
</summary><category term="video analysis"></category></entry><entry><title>Refining the business model</title><link href="https://jaantollander.github.io/SCI-C1000/bmc.html" rel="alternate"></link><published>2016-11-18T00:00:00+02:00</published><updated>2016-11-18T00:00:00+02:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-11-18:SCI-C1000/bmc.html</id><summary type="html">&lt;p&gt;This week the topic our of weekly meeting was refining the business model canvas and the monetization model.&lt;/p&gt;
&lt;div class="section" id="business-model-canvas"&gt;
&lt;h2&gt;Business model canvas&lt;/h2&gt;
&lt;div class="figure"&gt;
&lt;img alt="business model canvas" src="images/bmc.png" /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="monetization-model"&gt;
&lt;h2&gt;Monetization model&lt;/h2&gt;
&lt;div class="figure"&gt;
&lt;img alt="business model canvas" src="images/ansaintamalli.png" /&gt;
&lt;/div&gt;
&lt;p&gt;The monetization model consists of initial fixed cost and monthly maintenance and update fees. The initial cost varies case-by-case depending on the contract made with the customer. Facts taken into consideration when making the contract are the size and complexity of the area to be modelled.  To model larger area more photos are needed and constructing model from a large set of photos takes significant amounts of time and processing power. The size of the monthly costs are based on estimated amount of end users and the additional customer specific features. Computing the position and orientation of the users’ camera is computationally intensive task and therefore requires large investments in server architecture.&lt;/p&gt;
&lt;p&gt;We also considered other monetization models, but the SaaS (Software as a Service) approach was the most effective one. The single payment model was rejected because upkeep of the positioning servers is expensive and the customer is not willing to invest in server hardware. Also the possibility to take provision of the increased sales generated by the state-of-the-art advertising, but the idea was rejected because it is impossible to accurately measure the increased revenue caused by the advertising.&lt;/p&gt;
&lt;/div&gt;
</summary><category term="bmc"></category></entry><entry><title>Creating the Prototype</title><link href="https://jaantollander.github.io/SCI-C1000/prototype.html" rel="alternate"></link><published>2016-11-11T00:00:00+02:00</published><updated>2016-11-11T00:00:00+02:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-11-11:SCI-C1000/prototype.html</id><summary type="html">&lt;div class="section" id="creating-3d-models-with-visualsfm"&gt;
&lt;h2&gt;Creating 3D models with VisualSFM&lt;/h2&gt;
&lt;p&gt;Creating a 3D model from images with VisualSFM consists of three steps. &lt;a class="citation-reference" href="#visualsfm" id="id1"&gt;[VisualSFM]&lt;/a&gt;&lt;/p&gt;
&lt;div class="section" id="feature-detection-full-pairwise-image-matching"&gt;
&lt;h3&gt;1. Feature Detection &amp;amp; (Full) Pairwise Image Matching&lt;/h3&gt;
&lt;div class="figure"&gt;
&lt;img alt="match" src="images/vsfm/match.PNG" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;p&gt;Feature detection of the images finds similar features from each image in order to perform the pairwise image mathing. This operation determines where images are positioned in respect to one another&lt;/p&gt;
&lt;p&gt;Full pairwise image matching compares every image with every other image in order to do the matching. Full pairwise matching is the only way if we have completely random images but it is computationally expensive.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="sparse-reconstruction"&gt;
&lt;h3&gt;2. Sparse Reconstruction&lt;/h3&gt;
&lt;div class="figure"&gt;
&lt;img alt="sparse cloud" src="images/vsfm/sparse_cloud.PNG" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;p&gt;Sparse reconstruction constructs the point cloud from the matched images. It finds the spatial positions the images in the 3D space. Point cloud is required for indoor navigation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dense-reconstruction"&gt;
&lt;h3&gt;3. Dense Reconstruction&lt;/h3&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="https://jaantollander.github.io/3D-models/kaivuri/examples/kaivuri.html"&gt;&lt;img alt="dense reconstruction" src="images/vsfm/giphy.gif" style="width: 100%;" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;Dense reconstruction builds the full 3D model with textures from the sparse reconstruction. This is optional step for the indoor navigation but required for additional features that require 3D model such as &lt;em&gt;alternate reality (AR)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Live 3D model can be accessed by clicking the gif image above or &lt;a class="reference external" href="https://jaantollander.github.io/3D-models/kaivuri/examples/kaivuri.html"&gt;this link&lt;/a&gt;. It is displayed and rendered with Potree. &lt;a class="citation-reference" href="#potree" id="id2"&gt;[Potree]&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="d-model-of-learning-center-beta"&gt;
&lt;h2&gt;3D Model of Learning Center Beta&lt;/h2&gt;
&lt;p&gt;We took approximately 300 photos from the ground floor of the Learning Center beta and computed point cloud using VisualSFM. The results didn't quite turn out as expected.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="visualsfm point cloud" src="images/view.jpg" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;p&gt;VisualSFM generated 23 separate models from the photos. VisualSFM had trouble connecting photos shot with different cameras to each other and the relatively low number of photos considering the size of the space made it hard to combine them into a single model. VisualSFM is known to create many models even with ample amounts of photos due to the way that it builds the point cloud. One possible solution is to add more photos, but that would make the several hour computing time even longer.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="beta map" src="images/beta.PNG" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;p&gt;Most of the cameras were placed in the red circle. This is the most simple part of the floor. It's a large open space so it's easy to take enough overlapping photos. Closer to the entrance the space is divided into much smaller sections which makes it hard to capture photos with enough features for the algorithm to work properly.&lt;/p&gt;
&lt;p&gt;By changing the feature detection algorithm to search for more details and using a proprietary software for the point could reconstruction we were able to get a bit better results. The program was able to place around twice as many cameras and find more points.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="point cloud" src="images/pc.PNG" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="figure"&gt;
&lt;a class="reference external image-reference" href="https://jaantollander.github.io/3D-models/aula/examples/aula.html"&gt;&lt;img alt="model" src="images/aula.PNG" style="width: 100%;" /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;The results are only a slight improvement compared to the VisualSFM and generating a complete model of the whole floor would require many more photos. We estimate that a accurate model for indoor positioning purposes would require around 1000-2000 photos. Shooting a couple thousand photos is not a problem but with that many pictures feature recognition and matching becomes a problem. Without any additional knowledge of the photos every photo has to be matched with every other photo to find possible connections. This means that the computing time grows quadratically as the number of photos increases. With a powerful home computer processing a few thousand photos would take several days. We have to investigate ways to optimize our feature matching or find a powerful computing cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils citation" frame="void" id="visualsfm" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[VisualSFM]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Wu, Changchang. &amp;quot;VisualSFM: A visual structure from motion system.&amp;quot; (2011).&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="potree" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[Potree]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Potree | WebGL pointcloud renderer &lt;a class="reference external" href="http://www.potree.org/"&gt;http://www.potree.org/&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="prototype"></category></entry><entry><title>Value Proposition</title><link href="https://jaantollander.github.io/SCI-C1000/value-proposition.html" rel="alternate"></link><published>2016-11-04T00:00:00+02:00</published><updated>2016-11-04T00:00:00+02:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-11-04:SCI-C1000/value-proposition.html</id><summary type="html">&lt;div class="figure"&gt;
&lt;img alt="value proposition canvas" src="figures/value-proposition-canvas2.png" /&gt;
&lt;/div&gt;
&lt;div class="section" id="market-owners"&gt;
&lt;h2&gt;Market Owners&lt;/h2&gt;
&lt;div class="figure"&gt;
&lt;img alt="value proposition market owners" src="figures/value-proposition-market-owners.png" /&gt;
&lt;/div&gt;
&lt;!-- Customer Segment --&gt;
&lt;!-- ^^^^^^^^^^^^^^^^ --&gt;
&lt;!-- Customer Job --&gt;
&lt;!--  --&gt;
&lt;!-- * Buying food, groceries or other products --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Pains --&gt;
&lt;!--  --&gt;
&lt;!-- * Getting lost in large hyper markets and not finding needed products --&gt;
&lt;!-- * Wide variety of products can make finding special product harder --&gt;
&lt;!-- * The needed product being sold out --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Gains --&gt;
&lt;!--  --&gt;
&lt;!-- * Finding needed products with less effort and faster --&gt;
&lt;!-- * Benefiting from the best discount offers finding about best deals --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Value Proposition --&gt;
&lt;!-- ^^^^^^^^^^^^^^^^^ --&gt;
&lt;!-- Products and Services --&gt;
&lt;!--  --&gt;
&lt;!-- * Real time indoor navigation --&gt;
&lt;!-- * Guiding customer to the destination and aiding in finding special products --&gt;
&lt;!-- * Possibility of adding AR guides or advertisement --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Pain Relievers --&gt;
&lt;!--  --&gt;
&lt;!-- * AR guides help finding products faster --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Gain Creators --&gt;
&lt;!--  --&gt;
&lt;!-- * People will find the products they were looking leading to increased sales --&gt;
&lt;!-- * Better customer experience --&gt;
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="market-customers"&gt;
&lt;h2&gt;Market Customers&lt;/h2&gt;
&lt;div class="figure"&gt;
&lt;img alt="value proposition market customers" src="figures/value-proposition-market-customers.png" /&gt;
&lt;/div&gt;
&lt;!-- Customer segment --&gt;
&lt;!-- ^^^^^^^^^^^^^^^^ --&gt;
&lt;!-- Customer jobs --&gt;
&lt;!--  --&gt;
&lt;!-- * Filling the fridge --&gt;
&lt;!-- * Buying groceries and other needed products --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Pains --&gt;
&lt;!--  --&gt;
&lt;!-- * Being lost in a strange hypermarket and not finding needed products --&gt;
&lt;!-- * Wide variety of products so customer needs to put extra effort on finding the right one --&gt;
&lt;!-- * The needed product being sold out --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Gains --&gt;
&lt;!--  --&gt;
&lt;!-- * Benefiting from the best discount offers --&gt;
&lt;!-- * Finding needed product without further effort --&gt;
&lt;!--  --&gt;
&lt;!-- Value proposition --&gt;
&lt;!-- ^^^^^^^^^^^^^^^^^ --&gt;
&lt;!-- Products and services --&gt;
&lt;!--  --&gt;
&lt;!-- * Real-time indoor positioning and navigation with embedded augmented reality information about products --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Pain relievers --&gt;
&lt;!--  --&gt;
&lt;!-- * Offering replacing products when the one needed is sold out --&gt;
&lt;!-- * Navigation instructions directly to the needed product --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Gain creators --&gt;
&lt;!--  --&gt;
&lt;!-- * Real-time navigation --&gt;
&lt;!-- * Easily accessible information about different products and discount campaigns --&gt;
&lt;/div&gt;
&lt;hr class="docutils" /&gt;
&lt;div class="section" id="museums"&gt;
&lt;h2&gt;Museums&lt;/h2&gt;
&lt;div class="figure"&gt;
&lt;img alt="value proposition museums" src="figures/value-proposition-museums.png" /&gt;
&lt;/div&gt;
&lt;!-- Customer segment --&gt;
&lt;!-- ^^^^^^^^^^^^^^^^ --&gt;
&lt;!-- Customer jobs --&gt;
&lt;!--  --&gt;
&lt;!-- * Offering interesting exhibitions that attract people --&gt;
&lt;!-- * Teaching new things to visitors --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Pains --&gt;
&lt;!--  --&gt;
&lt;!-- * Not enough visitors to keep museum running --&gt;
&lt;!-- * People finding museums boring or old-fashioned in general --&gt;
&lt;!-- * Expensive investments --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Gains --&gt;
&lt;!--  --&gt;
&lt;!-- * Customer satisfaction --&gt;
&lt;!-- * Interesting and modern brand --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Value proposition --&gt;
&lt;!-- ^^^^^^^^^^^^^^^^^ --&gt;
&lt;!-- Products and services --&gt;
&lt;!--  --&gt;
&lt;!-- * Real-time indoor positioning and navigation with embedded augmented reality information about objects on exhibition --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Pain relievers --&gt;
&lt;!--  --&gt;
&lt;!-- * Not requiring any additional infrastructure to be installed --&gt;
&lt;!-- * Keeping up with time by digitizing services --&gt;
&lt;!--  --&gt;
&lt;!--  --&gt;
&lt;!-- Gain creators --&gt;
&lt;!--  --&gt;
&lt;!-- * Real-time navigation --&gt;
&lt;!-- * Easily accessible, interesting information about objects --&gt;
&lt;!-- * Interesting digital service, which is easy and fun to use --&gt;
&lt;/div&gt;
</summary><category term="value proposition"></category></entry><entry><title>Comparison Between Indoor Navigation Systems</title><link href="https://jaantollander.github.io/SCI-C1000/comparison.html" rel="alternate"></link><published>2016-10-28T00:00:00+03:00</published><updated>2016-10-28T00:00:00+03:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-10-28:SCI-C1000/comparison.html</id><summary type="html">&lt;div class="figure"&gt;
&lt;img alt="image of comparison" src="figures/comparison.png" /&gt;
&lt;/div&gt;
&lt;p&gt;There exits numerous competing methods for indoor navigation on the market, some more similar with out model than others. In this blog post these method are compared technically&lt;/p&gt;
&lt;div class="section" id="wifi-triangulation"&gt;
&lt;h2&gt;WIFI Triangulation&lt;/h2&gt;
&lt;p&gt;WiFi-positioning systems are built on two things: the received &lt;strong&gt;signal strength&lt;/strong&gt; of the device being positioned and the &lt;strong&gt;fingerprint&lt;/strong&gt; of the WiFi router sending the signal. This fingerprint can be, for example, the SSID &lt;a class="footnote-reference" href="#id3" id="id1"&gt;[1]&lt;/a&gt; or the MAC address &lt;a class="footnote-reference" href="#id4" id="id2"&gt;[2]&lt;/a&gt; of the WiFi router. In order to get positioning data with this system, the indoor areas have to be mapped with fingerprint/signal strength data matching some places and interpolating the data between the measured locations. Thus the accuracy of this method is dependent on the stability of the signal strength and the number of fingerprint/signal strength pairs.&lt;/p&gt;
&lt;p&gt;The strengths of this positioning method include the fact that it relies on existing infrastructure: WiFi can be nowadays found in almost any building. This method also ensures that the device making the location query can be connected to the database enabling the positioning, as without WiFi there is no positioning system at all. This positioning system can also be used in Internet of Things objects as most of them connect to the internet wirelessly anyway.&lt;/p&gt;
&lt;p&gt;As for weaknesses, the system needs WiFi to function, and in a world of near ubiquitous mobile networks (at least in Finland), the lack of WiFi in order to get positioning data is not that big of a problem. The accuracy of some systems is also of question, although some very accurate systems have been developed, such as the award winning &lt;a class="reference external" href="https://anyplace.cs.ucy.ac.cy/"&gt;Anyplace&lt;/a&gt;, which claims accuracy of less than 2 m. The initial layout of the building has to be created externally before the system can be deployed and as everyone surely knows, WiFi signals are sometimes finicky especially in rooms with thick walls.&lt;/p&gt;
&lt;table class="docutils footnote" frame="void" id="id3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Service set identifier (SSID)&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;A media access control address (MAC adress)&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="bluetooth-beacons"&gt;
&lt;h2&gt;Bluetooth Beacons&lt;/h2&gt;
&lt;p&gt;Another method for indoor positioning is the use of Bluetooth beacons scattered throughout the building in question. This method is in use for example at the main building here in Otaniemi in tandem with the Aalto Space app. The technique works rather simply: bluetooth low energy beacons are installed to a structure and their locations measured. As a device tries to determine its location with this technique, it simply triangulates its position using the received signal strength and individual fingerprints of the bluetooth beacons.&lt;/p&gt;
&lt;p&gt;The system is accurate and bluetooth functionality is found on most devices. Otherwise its strengths are similar to those of the WiFi technique: bluetooth connectivity can be found on most devices which also have WiFi.&lt;/p&gt;
&lt;p&gt;The weaknesses of this system are the need to install new hardware into the building as well as the need to maintain said hardware. Bluetooth signal range is also shorter than that of WiFi.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="magnetic-field-measurement"&gt;
&lt;h2&gt;Magnetic Field Measurement&lt;/h2&gt;
&lt;p&gt;Modern smartphones have quite excellent components to measure magnetic field in order to optimise connectivity. They are so accurate, in fact, that within a scope of a building there are very detectable fluctuations in surrounding magnetic field due to Earth’s own field as well as fields created by man-made devices. Thus each building has it’s own magnetic fingerprint and if the device knows which building it’s in, it can position itself by comparing its perceived magnetic field with a magnetic map of the building.&lt;/p&gt;
&lt;p&gt;This technique doesn’t need any infrastructure in order to function save the initial mapping of the magnetic field within the building. This process can be crowdsourced, as all one needs to map a building with an API is a smartphone with a working magnetic field strength meter. This means also that any device positioning itself with this technique can also be used to update the magnetic map, reducing the costs or altogether eliminating the need for external updates. A Finnish company, &lt;a class="reference external" href="https://www.indooratlas.com/"&gt;Indoor Atlas&lt;/a&gt;, developing this technique claims accuracy of less than 2 meters.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pedestrian-dead-reckoning-pdr"&gt;
&lt;h2&gt;Pedestrian Dead Reckoning (PDR)&lt;/h2&gt;
&lt;p&gt;Almost all smart devices come equipped with rather accurate acceleration sensors. Pedestrian dead reckoning techniques use these sensors to pick up positioning from the point where GPS signal is lost i.e. when entering a building. Individual steps taken by the user produce a certain kind of acceleration pattern and by approximating step length, the distance travelled can be measured with decent accuracy. Combining the step data with readings from the devices compass, the route taken by the device indoors can be reconstructed yielding the current position of the device. This technique is utilized in for example, aircraft.&lt;/p&gt;
&lt;p&gt;The strengths of this technique include the fact that only the end device is needed: if the device knows at some point its exact location (for example outside using GPS) it can approximate its route theoretically indefinitely even without an internet connection.&lt;/p&gt;
&lt;p&gt;The main weakness of the system is the accumulation of error: as each movement of the device is approximated and the route is constructed using a chain of these approximations, each step building on the last, eventually the position given by the system will be useless, even with small individual errors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="point-cloud-from-images"&gt;
&lt;h2&gt;Point-cloud from Images&lt;/h2&gt;
&lt;p&gt;The subject of this SCI-project, as one can read from previous posts, works by forming a point cloud based on images captured within the structure. When a device makes a location query by uploading a new photo of the interior of the building to the server, the image is compared with the existing point cloud, key features within the image are gathered and the location of the camera is solved as an  inversion problem. The new image is added to the point cloud.&lt;/p&gt;
&lt;p&gt;The main selling points of this technology are similar to those of magnetic field measurement: it needs no infrastructure and the updating and initial mapping of the structure can be crowdsourced. However, with this technique a full 3D model of the structure is constructed as opposed to a simple 2D map. This offers many applications beyond simple positioning, such as augmented reality guidance overlaid on the 3D model (guiding a shopper towards a product on the aisles of a store, for example).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="17%" /&gt;
&lt;col width="17%" /&gt;
&lt;col width="17%" /&gt;
&lt;col width="17%" /&gt;
&lt;col width="17%" /&gt;
&lt;col width="17%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Name&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Maintenance&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Power Source&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Other&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;WIFI Triangulation&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class="formula"&gt;5 − 30 &lt;span class="mathrm"&gt; m&lt;/span&gt;&lt;/span&gt; &lt;a class="footnote-reference" href="#id6" id="id5"&gt;[3]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Usually existing&lt;/td&gt;
&lt;td&gt;Remapping&lt;/td&gt;
&lt;td&gt;Device battery + AC&lt;/td&gt;
&lt;td&gt;Relies on existing infrastructure&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;Bluetooth Beacons&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class="formula"&gt;2 − 30 &lt;span class="mathrm"&gt; m&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;Hardware installation, Device management&lt;/td&gt;
&lt;td&gt;Remapping&lt;/td&gt;
&lt;td&gt;Device battery + AC&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;Magnetic Field Measurement&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class="formula"&gt;2 &lt;span class="mathrm"&gt; m&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;API + initial magnetic mapping&lt;/td&gt;
&lt;td&gt;Crowdsourced&lt;/td&gt;
&lt;td&gt;Device battery&lt;/td&gt;
&lt;td&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;Pedestrian Dead Reckoning&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;Varies&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;td&gt;Crowdsourced&lt;/td&gt;
&lt;td&gt;Device battery&lt;/td&gt;
&lt;td&gt;No additional devices / services needed&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;Point-cloud from Images&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;&lt;span class="formula"&gt;5 &lt;span class="mathrm"&gt; m&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;
&lt;td&gt;API + initial photoshoot&lt;/td&gt;
&lt;td&gt;Crowdsourced&lt;/td&gt;
&lt;td&gt;Device battery&lt;/td&gt;
&lt;td&gt;Creates 3D model to be used with AR etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- Footnotes --&gt;
&lt;table class="docutils footnote" frame="void" id="id6" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[3]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;depending on algorithms (&amp;gt;2m claimed by &lt;a class="reference external" href="https://anyplace.cs.ucy.ac.cy/"&gt;Anyplace&lt;/a&gt;)&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- Links --&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id7" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[4]&lt;/td&gt;&lt;td&gt;Sterling, Greg (Opus Research, I. . (2014). Magnetic Positioning, 1–8.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id8" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[5]&lt;/td&gt;&lt;td&gt;Zandbergen, P. A. (2009). Accuracy of iPhone locations: A comparison of assisted GPS, WiFi and cellular positioning. Transactions in GIS, 13(SUPPL. 1), 5–25. &lt;a class="reference external" href="http://doi.org/10.1111/j.1467-9671.2009.01152.x"&gt;http://doi.org/10.1111/j.1467-9671.2009.01152.x&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id9" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[6]&lt;/td&gt;&lt;td&gt;Bekkelien, A. (2012). Bluetooth indoor positioning. Master’s Thesis, University …, (March), 1. Retrieved from &lt;a class="reference external" href="http://cui.unige.ch/~deriazm/masters/bekkelien/Bekkelien_Master_Thesis.pdf"&gt;http://cui.unige.ch/~deriazm/masters/bekkelien/Bekkelien_Master_Thesis.pdf&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id10" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[7]&lt;/td&gt;&lt;td&gt;Beauregard, S., &amp;amp; Haas, H. (2006). Pedestrian dead reckoning: A basis for personal positioning. Positioning, Navigation and Communication, 27–35. &lt;a class="reference external" href="http://doi.org/10.1613/jair.301"&gt;http://doi.org/10.1613/jair.301&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id11" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[8]&lt;/td&gt;&lt;td&gt;Liu, H., Darabi, H., Banerjee, P., &amp;amp; Liu, J. (2007). Survey of wireless indoor positioning techniques and systems. IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews, 37(6), 1067–1080. &lt;a class="reference external" href="http://doi.org/10.1109/TSMCC.2007.905750"&gt;http://doi.org/10.1109/TSMCC.2007.905750&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary></entry><entry><title>Notes on SFM and Image Based Navigation Research</title><link href="https://jaantollander.github.io/SCI-C1000/research.html" rel="alternate"></link><published>2016-10-23T00:00:00+03:00</published><updated>2016-10-23T00:00:00+03:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-10-23:SCI-C1000/research.html</id><summary type="html">&lt;div class="figure"&gt;
&lt;img alt="image of iMoon software" src="images/2016-10-23_17-43-47_imoon.jpg" /&gt;
&lt;/div&gt;
&lt;p&gt;During our weekly meeting we decided to do some research on some already existing technologies (and those under constant development) for indoor localization, focusing on the work done by our supervising professor Antti Ylä-Jääski and his research group. With their iMoon system they have provably (&lt;a class="reference external" href="https://www.youtube.com/watch?v=sNvf7N_s59c&amp;amp;feature=youtu.be"&gt;youtube&lt;/a&gt;) succeeded in pinpointing indoor locations with sufficient accuracy using user-provided photos. Our team studied the technologies behind iMoon by reading an article published by Ylä-Jääski and his colleagues &lt;a class="citation-reference" href="#imoon" id="id1"&gt;[iMoon]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Indoor navigation is a topic that has been researched for several decades. Yet there isn’t a solution that could be widely utilized in every environment, for floor plans of public buildings are either not detailed enough or are not kept up to date. Many other methods also need a specific and often expensive infrastructure to be installed in the location. Thus an alternate method is direly needed. The method should be able to adapt to constantly changing environments and be efficient at the same time. Ylä-Jääski’s research group is developing a method to achieve the aforementioned requirements.&lt;/p&gt;
&lt;p&gt;iMoon technology is based on generating 3D-models from multiple pictures taken from a space and then matching new pictures with the model to determine a location. The model is generated using Structure from Motion technology which provides a point cloud of the environment. The photos can be crowdsourced and taken with differing equipment. While users take new photos to determine their location, these photos are also used to update the model.&lt;/p&gt;
&lt;p&gt;Because of varying quality and locations of crowdsourced photos, it’s unlikely that every corner of the area is covered in many good quality photos. This being the case, iMoon first creates new separate model from new images and then tries to merge separate model with existing one by comparing details in both models. This way the model can also adapt to small changes in environment caused by eg. moving furniture and other objects.&lt;/p&gt;
&lt;p&gt;iMoon also utilizes other technologies in addition to locating the user with pictures. This is necessary to keep the computation time at minimum and to provide a pleasant user experience. The time complexity of calculations increase with respect to the size of the model for more points need to compared with one another. In order to narrow down the raw location of the user iMoon uses Wi-Fi fingerprinting with K-nearest neighbours algorithm.&lt;/p&gt;
&lt;p&gt;In addition to Wi-fi fingerprinting, iMoon also utilizes user provided trajectories to generate original model and later increase navigation accuracy. Using information from motion sensors available in various smartphones, iMoon can calculate distance user has walked from last known location. The research group found out that the use of trajectories significantly improves performance of the service and quality of the generated model.&lt;/p&gt;
&lt;p&gt;iMoon is also capable of calculating navigation instructions and presenting them on top of existing images, which can be seen on youtube video linked earlier. Embedded navigation have positive impact on user friendliness, but they also provide base for using application with smart glasses like Google Glasses.&lt;/p&gt;
&lt;p&gt;The most relevant advantage of iMoon is that it runs on regular smartphones. This makes the technology affordable and user friendly. When compared to pure Wi-Fi positioning and image based positioning without Wi-Fi fingerprinting or user trajectories, iMoon clearly outperformed Wi-Fi positioning in every aspect, but was not significantly more accurate than pure image-based positioning. Both of them were able to locate user from &lt;span class="formula"&gt;95%&lt;/span&gt; of the photos sent with &lt;span class="formula"&gt;2&lt;/span&gt; meters of location error and &lt;span class="formula"&gt;6&lt;/span&gt; degrees of facing direction error. The main question here is about performance, and that’s where iMoon is superior when compared to pure image-based positioning. On average, iMoon was able to locate user in under &lt;span class="formula"&gt;4&lt;/span&gt; seconds but reference implementation took over &lt;span class="formula"&gt;40&lt;/span&gt; seconds, which is far from acceptable when considering actually usable system that someone would actually pay something.&lt;/p&gt;
&lt;p&gt;There are also many other technologies to use for indoor positioning, like Bluetooth beacons and analyzing magnetic field. We’ll do a bit more research before presenting those in detail, but we’ll get back to them in the next post.&lt;/p&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils citation" frame="void" id="imoon" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[iMoon]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Dong, J., Xiao, Y., Noreikis, M., Ou, Z., &amp;amp; Ylä-Jääski, A. (2015). iMoon : Using Smartphones for Image-based Indoor Navigation Categories and Subject Descriptors. Proceedings of the ACM Conference on Embedded Networked Sensor Systems, 85–97. &lt;a class="reference external" href="http://doi.org/10.1145/2809695.2809722"&gt;http://doi.org/10.1145/2809695.2809722&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary></entry><entry><title>Project plan</title><link href="https://jaantollander.github.io/SCI-C1000/project-plan.html" rel="alternate"></link><published>2016-10-14T00:00:00+03:00</published><updated>2016-10-14T00:00:00+03:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-10-14:SCI-C1000/project-plan.html</id><summary type="html">&lt;div class="figure" style="width: 100%"&gt;
&lt;img alt="pöhinä_garages" src="images/2016-10-14_10-37-27.jpg" /&gt;
&lt;/div&gt;
&lt;div class="section" id="introduction"&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;For outdoor use GPS (Global Positioning System) has established itself as a standard for locating objects and people. Unfortunately indoors the GPS does not often work and the accuracy is not enough for many applications. There are many alternative methods for indoor navigation that are based on different technologies such as Wi-Fi station triangulation or fingerprint locating or observing Earth's magnetic field. However, the lack of unified wireless infrastructure and standardisation interferes suitability of these technologies.&lt;/p&gt;
&lt;p&gt;Rapidly developing computing power of handheld devices enables new kinds of sophisticated solutions to locate users indoors. Technique called &lt;em&gt;Structure from Motion (SFM)&lt;/em&gt; makes it possible to form 3D model based on photographs or video images taken from several different locations and directions. Profiling points are identified from the photographs and 3D point cloud can be formed. This is used to construct the 3-dimensional model. The location of the user can be computed by matching the details from a photograph on the user's mobile device to the 3d-model and then calculating the users position using simple projection.&lt;/p&gt;
&lt;p&gt;Clear strength of the SFM technology when compared to other indoor positioning methods is that it works reliably, for example, using a standard smartphone camera. Both the formation of the model and utilization are possible with existing and affordable devices. Also, there is no need for separately installing expensive infrastructure in the space where indoor navigation is used.&lt;/p&gt;
&lt;p&gt;The purpose of this project is to find out&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Is photograph based indoor positioning system a viable option?&lt;/li&gt;
&lt;li&gt;Can this technology achieve adequate accuracy with available consumer devices such as smartphone cameras?&lt;/li&gt;
&lt;li&gt;Who would be willing to pay for such service, and what kind of synergies it would have with advertising or in the context of mobile games?&lt;/li&gt;
&lt;li&gt;We are also investigating if a small-scale prototype is realistically achievable in the scope of this project.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="potential-customers-and-end-users"&gt;
&lt;h2&gt;Potential Customers and End users&lt;/h2&gt;
&lt;p&gt;We try to direct the main focus of the project for solving a mundane and practical problems related to indoor positioning. Then end-users would likely be ordinary consumers. All smartphones and new smart devices in the future will be powerful enough to run the indoor positioning application. The only requirements are a camera and internet connectivity. This means that the potential customer base comprises all users of smart devices.&lt;/p&gt;
&lt;p&gt;One of the main customer groups are shopping centers and major hypermarket-class shops, which could take advantage of indoor positioning to provide a better customer experience, guidance service and presentation of advertisements. In addition to shops other large public places, such as musea might be interested in the possibilities for increasing the AR-elements to improve the customer experience. Elements in augmented reality could be signs, but also various commercials and reconstructions to provide customers with much more immersive museum experience.&lt;/p&gt;
&lt;p&gt;In addition to customers that utilize augmented reality it could also be used to quickly create 3D-models of limited size interior of buildings, for example, the virtual presentation of apartments. In this case, the advantage would be particularly affordability and ease of use, because the modeling is based entirely on the existing technology.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="scope-of-the-project"&gt;
&lt;h2&gt;Scope of the project&lt;/h2&gt;
&lt;div class="figure" style="width: 100%"&gt;
&lt;img alt="pöhinä2" src="images/2016-10-14_11-51-36.jpg" /&gt;
&lt;/div&gt;
&lt;p&gt;We will interview managers of retail stores and customers customers to find out, what kind of problems they have encountered and could more efficient positioning system ease these pains. Based on the analysis we seek to create a demo based on SFM technology and present a business model.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="50%" /&gt;
&lt;col width="50%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Time usage&lt;/td&gt;
&lt;td&gt;person hours&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Lectures and Presentations&lt;/td&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Meetings&lt;/td&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Information Collecting&lt;/td&gt;
&lt;td&gt;200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Interviews&lt;/td&gt;
&lt;td&gt;200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Programming, Modelling and Testing&lt;/td&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Documenting and Reporting&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Blog&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Total&lt;/td&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="schedule-and-milestones"&gt;
&lt;h2&gt;Schedule and Milestones&lt;/h2&gt;
&lt;p&gt;The project schedule is set to according scheduling based on the course. We have set deadlines for the various sub-regions as follows&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;caption&gt;Schedule&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col width="20%" /&gt;
&lt;col width="80%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Week&lt;/td&gt;
&lt;td&gt;Tasks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;Understanding the theoretical bases of the subject&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;42&lt;/td&gt;
&lt;td&gt;Booking of interviews (e-mail)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;43&lt;/td&gt;
&lt;td&gt;Study of customers' interest and interviews of&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;44&lt;/td&gt;
&lt;td&gt;Presentation 3 - presentation Guest interests and needs,&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;45&lt;/td&gt;
&lt;td&gt;The interviews were analyzed and the final decision about the application of&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;46&lt;/td&gt;
&lt;td&gt;Presentation 4 - presentation of business potential,&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;47&lt;/td&gt;
&lt;td&gt;Model ready&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;48&lt;/td&gt;
&lt;td&gt;Paragraph 5 - General Practice&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Schedule is monitored in weekly meetings, which are held on Thursdays at 10 o'clock.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="data-collecting"&gt;
&lt;h2&gt;Data Collecting&lt;/h2&gt;
&lt;p&gt;The collection of data is divided into two main phases: research of the theoretical basis based on the articles and fieldwork in the form of interviews. In the first phase, the objective is to provide a comprehensive overview of the current state of technology, the opportunities and challenges as well as create a realistic idea of the level of complexity for the produced demo. Articles form the basis of the concepts of the interviews. The interviews will be carried out either by phone or physically on site and, depending on the location and the interviewee's schedule. The purpose of the interviews is to identify the potential customer interest in the concept and at the same time to get a new perspective for the development of the concept. The final concept and demo is created on the basis of issues and areas of development collected in the interviews .&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="risks"&gt;
&lt;h2&gt;Risks&lt;/h2&gt;
&lt;p&gt;We have mapped the risks related to the project and to prepare for them as follows&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="40%" /&gt;
&lt;col width="20%" /&gt;
&lt;col width="40%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Risks related to the project&lt;/td&gt;
&lt;td&gt;The level of risk&lt;/td&gt;
&lt;td&gt;Measures to prevent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Complexity of the prototype&lt;/td&gt;
&lt;td&gt;Large&lt;/td&gt;
&lt;td&gt;Detection of its feasibility early enough.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Data loss&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Version Management / Backup&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Male labor force reduction&lt;/td&gt;
&lt;td&gt;Small&lt;/td&gt;
&lt;td&gt;Is noted when planning schedules&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Failure of the scheduling&lt;/td&gt;
&lt;td&gt;Medium-sized&lt;/td&gt;
&lt;td&gt;Sub-project Monitoring the progress of our weekly meetings&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;The interviewees can not be found&lt;/td&gt;
&lt;td&gt;Small&lt;/td&gt;
&lt;td&gt;In due time started searching for the interviewees a large number of the interviewees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;The interviews are not useful&lt;/td&gt;
&lt;td&gt;Small&lt;/td&gt;
&lt;td&gt;Carefully prepared questions, in order to obtain answers to the problems being&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Time management&lt;/td&gt;
&lt;td&gt;Small&lt;/td&gt;
&lt;td&gt;The division of responsibilities, scheduling and deadlines, a weekly focus of evaluation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class="section" id="responsibilities"&gt;
&lt;h2&gt;Responsibilities&lt;/h2&gt;
&lt;p&gt;Our group consists of seven people, whom we have shared responsibilities roughly as follows.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="30%" /&gt;
&lt;col width="70%" /&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Aapo&lt;/td&gt;
&lt;td&gt;Interviews, photographing, stand&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Markus&lt;/td&gt;
&lt;td&gt;Interviews, documenting, presentations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Jaan&lt;/td&gt;
&lt;td&gt;Blog, modelling, testing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Misamatti&lt;/td&gt;
&lt;td&gt;Modelling, data collection, leading the team&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Antti&lt;/td&gt;
&lt;td&gt;Analysis from the Interviews, Interviewing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Lauri&lt;/td&gt;
&lt;td&gt;Data collection, interviews&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Juhani&lt;/td&gt;
&lt;td&gt;Data collection, modelling&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="Week 2"></category><category term="project plan"></category></entry><entry><title>Meeting with Professor Antti Ylä-Jääski</title><link href="https://jaantollander.github.io/SCI-C1000/meeting-with-professor-antti-yla-jaaski.html" rel="alternate"></link><published>2016-09-29T00:00:00+03:00</published><updated>2016-09-29T00:00:00+03:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-09-29:SCI-C1000/meeting-with-professor-antti-yla-jaaski.html</id><summary type="html">&lt;p&gt;We had a meeting with out supervising professor Antti Ylä-Jääski and two his colleagues. We had a discussed about the &lt;em&gt;structure of motion (SFM)&lt;/em&gt; technology &lt;a class="citation-reference" href="#opensfm" id="id1"&gt;[OpenSFM]&lt;/a&gt;, &lt;a class="citation-reference" href="#opengvs" id="id2"&gt;[OpenGVS]&lt;/a&gt;, &lt;a class="citation-reference" href="#visualsfm" id="id3"&gt;[VisualSFM]&lt;/a&gt;, its applications to real life and his group's research on the subject. They had succesfully applied the technology to indoor modelling and navigation &lt;a class="citation-reference" href="#imoon" id="id4"&gt;[iMoon]&lt;/a&gt;, &lt;a class="citation-reference" href="#imoon2" id="id5"&gt;[iMoon2]&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils citation" frame="void" id="imoon" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id4"&gt;[iMoon]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://dl.acm.org/citation.cfm?id=2809722"&gt;http://dl.acm.org/citation.cfm?id=2809722&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="imoon2" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id5"&gt;[iMoon2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://youtu.be/sNvf7N_s59c"&gt;https://youtu.be/sNvf7N_s59c&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="opensfm" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[OpenSFM]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://github.com/mapillary/OpenSfM"&gt;https://github.com/mapillary/OpenSfM&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="opengvs" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[OpenGVS]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://devmaster.net/devdb/engines/opengvs"&gt;http://devmaster.net/devdb/engines/opengvs&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="visualsfm" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id3"&gt;[VisualSFM]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="http://ccwu.me/vsfm/"&gt;http://ccwu.me/vsfm/&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="Week 1-2"></category></entry><entry><title>First Group Meeting</title><link href="https://jaantollander.github.io/SCI-C1000/first-group-meeting.html" rel="alternate"></link><published>2016-09-28T00:00:00+03:00</published><updated>2016-09-28T00:00:00+03:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-09-28:SCI-C1000/first-group-meeting.html</id><summary type="html">&lt;img alt="picture about first group meeting" src="images/20160928_162236.jpg" style="height: 400px;" /&gt;
&lt;p&gt;We met at the CS building to discuss the first steps of our project. After an intesive photoshoot to capture our freely flowing creative process, we soon arrived at a satisfactory title for our party: &lt;strong&gt;3+4Dudes&lt;/strong&gt;. After some brief discussion about blog-keeping tools, we began talking about the scope of our project.&lt;/p&gt;
&lt;p&gt;Despite our previous research finding that &lt;a class="citation-reference" href="#lidar" id="id1"&gt;[LIDAR]&lt;/a&gt; is a superior tool compared to our &lt;a class="citation-reference" href="#sfm" id="id2"&gt;[SFM]&lt;/a&gt; tools, one of our group with experience in a company working with SFM technique protested: the company was of the opinion that SFM offers a sufficient degree of detail while being &lt;strong&gt;a lot faster and cheaper&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="section" id="objects-vs-structures"&gt;
&lt;h2&gt;Objects vs Structures&lt;/h2&gt;
&lt;p&gt;Structures&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Inside vs outside&lt;/li&gt;
&lt;li&gt;Navigation inside stores&lt;/li&gt;
&lt;li&gt;Furniture positioning&lt;/li&gt;
&lt;li&gt;Appartement showings virtually&lt;/li&gt;
&lt;li&gt;Outside: architechture offices could hire a guy w/ drone to scout a location for a new building or expansion&lt;/li&gt;
&lt;li&gt;Maastonkartoitus peräkylille&lt;/li&gt;
&lt;li&gt;UNESCO virtual archive&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Objects&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Take your belongings with you to the virtual world&lt;/li&gt;
&lt;li&gt;Did not think of good application ideas&lt;/li&gt;
&lt;li&gt;Human 3d-photography for officials and consumers&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils citation" frame="void" id="lidar" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[LIDAR]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Lidar"&gt;https://en.wikipedia.org/wiki/Lidar&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils citation" frame="void" id="sfm" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[SFM]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Structure_from_motion"&gt;https://en.wikipedia.org/wiki/Structure_from_motion&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="Week 1-2"></category></entry><entry><title>Week 1: Starting Up</title><link href="https://jaantollander.github.io/SCI-C1000/week-1-starting-up.html" rel="alternate"></link><published>2016-09-23T00:00:00+03:00</published><updated>2016-09-23T00:00:00+03:00</updated><author><name>Jaan Tollander de Balsch</name></author><id>tag:jaantollander.github.io,2016-09-23:SCI-C1000/week-1-starting-up.html</id><summary type="html">&lt;div class="section" id="plans-and-goals-for-the-first-week"&gt;
&lt;h2&gt;Plans and Goals for the first week&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Contacts&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Meeting up with our contact professor&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Project Branding&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Creating a project blog&lt;/li&gt;
&lt;li&gt;Name the project&lt;/li&gt;
&lt;li&gt;Design a logo and icon&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Project Managment&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Planning the allocation of time&lt;/li&gt;
&lt;li&gt;Keeping track of workhours&lt;/li&gt;
&lt;li&gt;Flowchart of the project&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Project&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Defining the problem and how to approach it&lt;/li&gt;
&lt;li&gt;Limiting the size of the solution to the problem&lt;/li&gt;
&lt;li&gt;Figuring out the possible customers for this technology&lt;/li&gt;
&lt;li&gt;Defining the main goal of the project&lt;/li&gt;
&lt;li&gt;List of open source technologies that can create 3D models from photographs&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="creating-the-project-blog"&gt;
&lt;h2&gt;Creating the Project Blog&lt;/h2&gt;
&lt;p&gt;Created the project blog &lt;em&gt;(the one you are reading right now)&lt;/em&gt;.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;About&lt;/strong&gt; page contains some general information about the project&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Contact&lt;/strong&gt; page contains information about the authors of the project.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Source code of this blog is hosted at &lt;a class="reference external" href="https://github.com/jaantollander/SCI-C1000"&gt;GitHub&lt;/a&gt; and the blog it self is in the project &lt;a class="reference external" href="https://jaantollander.github.io/SCI-C1000/"&gt;GitHub pages&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="d-reconstruction-from-photos"&gt;
&lt;h2&gt;3D Reconstruction from Photos&lt;/h2&gt;
&lt;p&gt;When taking traditional photos of 3-dimensional world, it is projected into 2-dimensional surface and the depth is lost. In order to restore this lost dimension, one way to reconstuct it is as inversion problem, meaning reconstruction from multiple images &lt;a class="footnote-reference" href="#id3" id="id1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="comparison-with-other-technologies"&gt;
&lt;h3&gt;Comparison with Other Technologies&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;LIDAR is a surveying method that measures distance to a target by illuminating that target with a laser light&lt;/em&gt; &lt;a class="footnote-reference" href="#id4" id="id2"&gt;[2]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pros and cons comparing 3D recostruction from images versus LIDAR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Pros&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Cheaper than LIDAR&lt;/li&gt;
&lt;li&gt;More available to consumers&lt;/li&gt;
&lt;li&gt;Is able to create texture and colors for the surfaces&lt;/li&gt;
&lt;li&gt;Images can be analysed without visiting the place.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Cons&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;A lot less accurate&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="potential-uses-and-customers"&gt;
&lt;h3&gt;Potential Uses and Customers&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Industry&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Not accurate enough to replace LIDAR&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Constumers&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Decoration app&lt;/li&gt;
&lt;li&gt;Games&lt;/li&gt;
&lt;li&gt;Navigation with smart glasses inside buildings&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Architects&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Creating quick drafts when full precision is not needed&lt;/li&gt;
&lt;li&gt;Displaying different choices for decoration in virtual or alternate reality&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Other&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;Building safety design&lt;/li&gt;
&lt;li&gt;Virtual models of existing buildings&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="references"&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="id3" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/3D_reconstruction_from_multiple_images"&gt;https://en.wikipedia.org/wiki/3D_reconstruction_from_multiple_images&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class="docutils footnote" frame="void" id="id4" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#id2"&gt;[2]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Lidar"&gt;https://en.wikipedia.org/wiki/Lidar&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</summary><category term="Week 1"></category></entry></feed>